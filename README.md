# ğŸ¥ Drum Notation Backend

A comprehensive FastAPI backend for automatic drum transcription from video content, featuring advanced audio processing, AI-powered analysis, and professional notation generation.

## ğŸ“‹ Table of Contents

- [ğŸ¯ Project Overview](#-project-overview)
- [ğŸ—ï¸ Architecture](#ï¸-architecture)
- [ğŸš€ Getting Started](#-getting-started)
- [ğŸ“Š Database Schema](#-database-schema)
- [ğŸ› ï¸ API Endpoints](#ï¸-api-endpoints)
- [ğŸ¬ Processing Workflow](#-processing-workflow)
- [ğŸ¤– OpenAI Integration](#-openai-integration)
- [ğŸ” Authentication & Security](#-authentication--security)
- [ğŸ“ Project Structure](#-project-structure)
- [ğŸ§ª Testing](#-testing)
- [ğŸ”§ Configuration](#-configuration)
- [ğŸš€ Deployment](#-deployment)
- [ğŸ¤ Contributing](#-contributing)

## ğŸ¯ Project Overview

### What It Does
The Drum Notation Backend automatically analyzes drum performance videos and generates professional musical notation. It combines advanced audio processing, computer vision, and AI-powered analysis to provide comprehensive drum transcription services.

### Key Features
- **ğŸµ Audio Processing**: Extract and analyze audio from video files
- **ğŸ¥ Drum Detection**: Identify and classify drum events with high accuracy
- **ğŸ›ï¸ Source Separation**: Isolate individual drum components
- **ğŸ¼ Notation Generation**: Create professional drum notation
- **ğŸ¤– AI Enhancement**: OpenAI-powered musical analysis and insights
- **âš™ï¸ Async Processing**: Background job processing with real-time updates
- **ğŸ” Secure APIs**: JWT authentication with role-based access
- **ğŸ“Š Comprehensive Analytics**: Detailed performance metrics and insights

### Technology Stack
- **Backend**: FastAPI (Python 3.11+)
- **Database**: PostgreSQL with SQLAlchemy ORM
- **Audio Processing**: librosa, scipy, soundfile, FFmpeg
- **AI Integration**: OpenAI GPT-4 for musical analysis
- **Authentication**: JWT with bcrypt password hashing
- **Background Jobs**: Async task processing
- **Documentation**: Interactive OpenAPI/Swagger UI

## ğŸ—ï¸ Architecture

### System Components

The backend follows a modular, async-first architecture:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                           FastAPI Application                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Authentication â”‚  User Management â”‚  Role Management           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚               Media Management (Videos & Audio)                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Audio Processing â”‚  Drum Detection â”‚  Source Separation        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚              Notation Generation â”‚  OpenAI Integration          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                      Background Jobs Queue                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                      PostgreSQL Database                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Core Modules

- **`app/modules/users/`** - User management and profiles
- **`app/modules/roles/`** - Role-based access control
- **`app/modules/media/`** - Video and audio file management
- **`app/modules/audio_processing/`** - Audio analysis and drum detection
- **`app/modules/notation/`** - Notation generation and management
- **`app/modules/jobs/`** - Background task processing
- **`app/modules/vision/`** - Computer vision components
- **`app/core/`** - Core services (OpenAI, security, config)

### Status: âœ… **PRODUCTION READY**
All modules are implemented, tested, and operational.

## ğŸš€ Getting Started

### Prerequisites
- Python 3.11+
- PostgreSQL 13+
- FFmpeg (system dependency)
- OpenAI API Key (optional, for AI features)

### Installation

1. **Clone the repository**
   ```bash
   git clone <repository-url>
   cd Drum-Notation-Backend
   ```

2. **Create virtual environment**
   ```bash
   python -m venv dnvenv
   source dnvenv/bin/activate  # On Windows: dnvenv\Scripts\activate
   ```

3. **Install dependencies**
   ```bash
   pip install -r requirements.txt
   ```

4. **Setup database**
   ```bash
   # Create PostgreSQL database
   createdb drum_notation
   
   # Run migrations
   alembic upgrade head
   ```

5. **Configure environment**
   ```bash
   cp .env.example .env
   # Edit .env with your configuration
   ```

6. **Start the server**
   ```bash
   uvicorn app.main:app --reload --host 0.0.0.0 --port 8000
   ```

7. **Access the API**
   - API Documentation: http://localhost:8000/docs
   - Health Check: http://localhost:8000/

## ğŸ“Š Database Schema

### Core Tables

```sql
-- User Management
users (id, username, email, hashed_password, created_at, updated_at)
roles (id, name, description, permissions)
user_roles (user_id, role_id)

-- Media Management
videos (id, user_id, filename, file_path, duration, status, metadata)
audio_files (id, video_id, filename, file_path, sample_rate, channels)

-- Processing
processing_jobs (id, user_id, job_type, status, progress, result_data)

-- Notation
notations (id, video_id, tempo, time_signature, notation_json)
openai_enrichments (id, notation_id, prompt_hash, model, input_json, output_json)
```

### Key Relationships
- Users â†’ Videos (one-to-many)
- Videos â†’ AudioFiles (one-to-many)  
- Videos â†’ Notations (one-to-one)
- Notations â†’ OpenAI Enrichments (one-to-many)
- Users â†’ Processing Jobs (one-to-many)

## ğŸ› ï¸ API Endpoints

### ğŸ” Authentication
- `POST /auth/register` - User registration
- `POST /auth/login` - User login
- `POST /auth/refresh` - Refresh JWT token

### ğŸ‘¥ User Management  
- `GET /users/me` - Get current user profile
- `PUT /users/me` - Update user profile
- `GET /users/{user_id}` - Get user by ID

### ğŸ¬ Media Management
- `POST /videos/upload` - Upload video file
- `GET /videos` - List user's videos
- `GET /videos/{video_id}` - Get video details
- `DELETE /videos/{video_id}` - Delete video

### âš™ï¸ Processing Jobs
- `GET /jobs/my-jobs` - List user's jobs  
- `GET /jobs/{job_id}` - Get job status
- `POST /jobs/{job_id}/cancel` - Cancel job

### ğŸµ Audio Processing
- `POST /audio/extract/{video_id}` - Extract audio from video
- `GET /audio/extract/{video_id}/status` - Check extraction status
- `POST /audio/detect-drums/{video_id}` - Detect drum events
- `POST /audio/detect-drums-advanced/{video_id}` - Advanced detection
- `POST /audio/separate-sources/{video_id}` - Source separation
- `POST /audio/create-stems/{video_id}` - Create professional stems
- `POST /audio/enhance-drums/{video_id}` - Enhance drum elements
- `GET /audio/analysis/comprehensive/{video_id}` - Complete analysis
- `GET /audio/features/{video_id}` - Extract audio features

### ğŸ¼ Notation & AI
- `POST /notation/generate/{video_id}` - Generate notation
- `GET /notation/{notation_id}` - Get notation
- `POST /notation/{notation_id}/analyze` - AI analysis
- `POST /notation/{notation_id}/practice-guide` - Practice instructions
- `POST /notation/{notation_id}/style-classify` - Style classification

## ğŸ¬ Processing Workflow

### 1. Video Upload
```python
# User uploads video file
POST /videos/upload
â†’ Creates Video record in database
â†’ Returns video_id for subsequent processing
```

### 2. Audio Extraction  
```python
# Extract audio from video
POST /audio/extract/{video_id}
â†’ Creates background job
â†’ Extracts audio using FFmpeg
â†’ Saves AudioFile record
```

### 3. Drum Detection
```python
# Detect and classify drum events
POST /audio/detect-drums-advanced/{video_id}
â†’ Analyzes audio for drum onsets
â†’ Classifies drum types (kick, snare, hihat, etc.)
â†’ Calculates velocity and confidence scores
```

### 4. Generate Notation
```python
# Create musical notation
POST /notation/generate/{video_id}
â†’ Processes detected events
â†’ Quantizes to musical grid
â†’ Generates notation JSON
```

### 5. AI Enhancement
```python
# Get AI-powered insights
POST /notation/{notation_id}/analyze  
â†’ Sends notation to OpenAI
â†’ Receives musical analysis and insights
â†’ Stores enrichment data
```

## ğŸ¤– OpenAI Integration

### Features
- **Pattern Analysis**: Complexity scoring, rhythm analysis
- **Style Classification**: Genre identification with confidence scores  
- **Practice Instructions**: Personalized learning recommendations
- **Musical Insights**: Technical analysis and improvement tips

### Configuration
```python
# Enable OpenAI features
OPENAI_API_KEY=your_api_key_here
OPENAI_MODEL=gpt-4
OPENAI_MAX_TOKENS=2000
```

### AI Enhancement Types

1. **Drum Pattern Analysis**
   - Complexity assessment (beginner/intermediate/advanced)
   - Key pattern identification
   - Tempo consistency analysis
   - Rhythmic density calculation

2. **Style Classification**
   - Genre detection (rock, jazz, latin, etc.)
   - Confidence scoring
   - Musical characteristics identification

3. **Practice Recommendations**
   - Skill level assessment
   - Targeted exercises
   - Technical improvement suggestions

### Example AI Response
```json
{
  "pattern_analysis": {
    "complexity": "intermediate", 
    "key_patterns": ["basic rock beat", "hi-hat variations"],
    "tempo_consistency": 0.92,
    "rhythmic_density": "moderate"
  },
  "style_classification": {
    "primary_genre": "rock",
    "confidence": 0.87,
    "characteristics": ["steady kick pattern", "snare on 2 and 4"]
  },
  "practice_instructions": {
    "difficulty": "intermediate",
    "focus_areas": ["hi-hat control", "dynamic variation"],
    "exercises": ["practice ghost notes", "work on limb independence"]
  }
}
```

## ğŸ” Authentication & Security

### JWT Token Authentication
- Secure user authentication with JWT tokens
- Token refresh mechanism
- Role-based access control (RBAC)

### Security Features
- Password hashing with bcrypt
- Request rate limiting
- CORS protection
- SQL injection prevention via SQLAlchemy ORM
- Input validation with Pydantic schemas

## ğŸ“ Project Structure

```
Drum-Notation-Backend/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ main.py                    # FastAPI application entry point
â”‚   â”œâ”€â”€ core/                      # Core services and configuration
â”‚   â”‚   â”œâ”€â”€ config.py             # Environment configuration
â”‚   â”‚   â”œâ”€â”€ database.py           # Database connection
â”‚   â”‚   â”œâ”€â”€ security.py           # Authentication & authorization
â”‚   â”‚   â””â”€â”€ openai_service.py     # OpenAI integration
â”‚   â”œâ”€â”€ db/
â”‚   â”‚   â”œâ”€â”€ base.py              # Database base configuration
â”‚   â”‚   â””â”€â”€ models.py            # Model registry
â”‚   â”œâ”€â”€ modules/                  # Feature modules
â”‚   â”‚   â”œâ”€â”€ users/               # User management
â”‚   â”‚   â”œâ”€â”€ roles/               # Role-based access control
â”‚   â”‚   â”œâ”€â”€ media/               # Video & audio file management
â”‚   â”‚   â”œâ”€â”€ audio_processing/    # Audio analysis & drum detection
â”‚   â”‚   â”œâ”€â”€ notation/            # Notation generation & AI features
â”‚   â”‚   â”œâ”€â”€ jobs/                # Background task processing
â”‚   â”‚   â””â”€â”€ vision/              # Computer vision components
â”‚   â””â”€â”€ shared/                   # Shared utilities and base classes
â”œâ”€â”€ alembic/                      # Database migrations
â”œâ”€â”€ tests/                        # Test suite
â”œâ”€â”€ requirements.txt              # Python dependencies
â”œâ”€â”€ alembic.ini                  # Database migration config
â”œâ”€â”€ pytest.ini                  # Test configuration
â””â”€â”€ README.md                    # This file
```

## ğŸ§ª Testing

### Run Tests
```bash
# Run all tests
pytest

# Run specific module tests
pytest tests/test_openai_integration.py

# Run with coverage
pytest --cov=app tests/

# Run integration tests (requires API keys)
pytest -m integration
```

### Test Categories
- **Unit Tests**: Individual component testing
- **Integration Tests**: OpenAI and database integration  
- **Audio Processing Tests**: Audio analysis validation
- **API Tests**: Endpoint functionality

### Manual API Testing
Access the interactive API documentation:
- **Swagger UI**: http://localhost:8000/docs
- **ReDoc**: http://localhost:8000/redoc

## ğŸ”§ Configuration

### Environment Variables (.env)
```bash
# Database
DATABASE_URL=postgresql://user:password@localhost/drum_notation

# Security
SECRET_KEY=your-secret-key-here
ACCESS_TOKEN_EXPIRE_MINUTES=30

# OpenAI (Optional)
OPENAI_API_KEY=your-openai-api-key
OPENAI_MODEL=gpt-4
OPENAI_MAX_TOKENS=2000

# File Storage
UPLOAD_DIR=./uploads
TEMP_DIR=./temp
MAX_FILE_SIZE_MB=500

# Audio Processing
DEFAULT_SAMPLE_RATE=44100
DEFAULT_CHANNELS=1
```

### Key Configuration Notes
- **SECRET_KEY**: Generate a strong secret key for JWT tokens
- **DATABASE_URL**: PostgreSQL connection string
- **OPENAI_API_KEY**: Required for AI-powered features
- **File paths**: Ensure upload/temp directories exist and are writable

## ğŸš€ Deployment

### Docker Deployment
```yaml
version: '3.8'
services:
  app:
    build: .
    ports:
      - "8000:8000"
    environment:
      - DATABASE_URL=postgresql://postgres:password@db/drum_notation
    depends_on:
      - db
    volumes:
      - ./uploads:/app/uploads
      - ./temp:/app/temp

  db:
    image: postgres:13
    environment:
      POSTGRES_DB: drum_notation
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: password
    volumes:
      - postgres_data:/var/lib/postgresql/data

volumes:
  postgres_data:
```

### Production Checklist
- [ ] Set strong SECRET_KEY
- [ ] Configure secure DATABASE_URL  
- [ ] Set up SSL/HTTPS
- [ ] Configure CORS origins
- [ ] Set up file storage (S3, etc.)
- [ ] Configure logging and monitoring
- [ ] Set up backup strategy
- [ ] Enable rate limiting
- [ ] Configure environment-specific settings

## ğŸ“ˆ Roadmap

### âœ… Completed (Current State)
- âœ… Complete FastAPI backend with all modules
- âœ… User authentication and authorization
- âœ… Video upload and audio extraction
- âœ… Advanced drum detection and classification
- âœ… Source separation and audio enhancement
- âœ… Notation generation pipeline
- âœ… OpenAI integration for musical analysis
- âœ… Background job processing
- âœ… Comprehensive API documentation
- âœ… Database schema and migrations
- âœ… Security and validation
- âœ… Error handling and logging

### ğŸ”„ Ready for Integration
- ğŸ”„ External ML model integration (your responsibility)
- ğŸ”„ Frontend application connection
- ğŸ”„ Production deployment

### ğŸ“‹ Future Enhancements
- ğŸ“‹ Real-time WebSocket processing updates
- ğŸ“‹ MIDI export functionality
- ğŸ“‹ Batch processing capabilities
- ğŸ“‹ Advanced notation features (dynamics, articulations)
- ğŸ“‹ Mobile API optimizations

## ğŸ¤ Contributing

### Development Setup
1. Follow the installation guide above
2. Install development dependencies: `pip install -r requirements-dev.txt`
3. Set up pre-commit hooks: `pre-commit install`
4. Run tests before submitting: `pytest`

### Code Standards
- **Style**: Follow PEP 8 with Black formatting
- **Type Hints**: Use comprehensive type annotations
- **Documentation**: Document all public APIs
- **Testing**: Write tests for new features
- **Commits**: Use conventional commit messages

## ğŸ“ Support & Contact

For questions, issues, or contributions:
- ğŸ“§ **Issues**: Create GitHub issues for bugs or feature requests
- ğŸ“– **Documentation**: Check `/docs` endpoint for API reference
- ğŸ§ª **Testing**: Run test suite for validation

---

**Status**: âœ… **PRODUCTION READY** - Complete backend implementation ready for integration and deployment.

**Last Updated**: January 2025